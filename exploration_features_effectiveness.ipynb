{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "610a71d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a11d57d",
   "metadata": {},
   "source": [
    "## Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1052bee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_rev = pd.read_csv(\"data/train_data_REV_with_text.csv\")\n",
    "df_test_rev = pd.read_csv(\"data/test_data_REV_with_text.csv\")\n",
    "df_train_rev = df_train_rev.sort_values(by=['datacqtr', 'tic']).reset_index(drop=True)\n",
    "df_test_rev = df_test_rev.sort_values(by=['datacqtr', 'tic']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a33896d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NA\n",
    "\n",
    "df_train_rev = df_train_rev.dropna()\n",
    "df_test_rev = df_test_rev.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "318ce54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_training_dataset(df1: pd.DataFrame, df2:pd.DataFrame, subset: list, y_value=\"Total Current Operating Revenue\"):\n",
    "    X_train = df1[subset].copy().to_numpy()\n",
    "    y_train = df1[y_value].copy().to_numpy()\n",
    "\n",
    "    X_test = df2[subset].copy().to_numpy()\n",
    "    y_test = df2[y_value].copy().to_numpy()\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def train_ridge_regression(X_train, y_train, X_test, y_test, return_values=False):\n",
    "    # Define the model\n",
    "    ridge = Ridge()\n",
    "\n",
    "    # Define the hyperparameter grid\n",
    "    param_grid = {\n",
    "        # 'alpha': [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "        'alpha': [1.0]\n",
    "    }\n",
    "\n",
    "    # Setup GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=ridge,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Fit the grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best model from grid search\n",
    "    best_ridge = grid_search.best_estimator_\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = best_ridge.predict(X_test)\n",
    "\n",
    "    print(f\"Best alpha: {grid_search.best_params_['alpha']}\")\n",
    "    \n",
    "    if return_values:\n",
    "        return y_test, y_pred\n",
    "\n",
    "    # Evaluate the model\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Ridge Regression Results:\")\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "    print(f\"Test MAE: {mae:.4f}\")\n",
    "    print(f\"Test R²: {r2:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "def train_linear_regression(X_train, y_train, X_test, y_test, return_values=False):\n",
    "    # Define the model\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    if return_values:\n",
    "        return y_test, y_pred\n",
    "\n",
    "    # Evaluate the model\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Linear Regression Results:\")\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "    print(f\"Test MAE: {mae:.4f}\")\n",
    "    print(f\"Test R²: {r2:.4f}\")\n",
    "\n",
    "\n",
    "def train_decision_tree(X_train, y_train, X_test, y_test, random_state=42, return_values=False):\n",
    "    # # # Define the model\n",
    "    tree = DecisionTreeRegressor(random_state=random_state)\n",
    "\n",
    "    # # Define the hyperparameter grid\n",
    "    param_grid = {\n",
    "        'max_depth': [3, 5, 10, 20, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    # tree  = RandomForestRegressor(random_state=random_state)\n",
    "    # param_grid = {\n",
    "    #     'max_depth': [3, 5, 10, 20, None],\n",
    "    #     'min_samples_split': [2, 5, 10],\n",
    "    #     'min_samples_leaf': [1, 2, 4],\n",
    "    # }\n",
    "\n",
    "    # Setup GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=tree,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,                # 5-fold cross-validation\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1            # Use all cores\n",
    "    )\n",
    "\n",
    "    # Fit the grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best model from grid search\n",
    "    best_tree = grid_search.best_estimator_\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = best_tree.predict(X_test)\n",
    "\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    \n",
    "    if return_values:\n",
    "        return y_test, y_pred\n",
    "\n",
    "    # Evaluate the model\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "    print(f\"Test MAE: {mae:.4f}\")\n",
    "    print(f\"Test R²: {r2:.4f}\")\n",
    "    # print(f\"Test R²: {r2}\")\n",
    "    # print(y_test)\n",
    "    # print(y_pred)\n",
    "\n",
    "\n",
    "def train_lightgbm(X_train, y_train, X_test, y_test, return_values=False, random_state=42):\n",
    "    # Define the model\n",
    "    lgbm = LGBMRegressor(random_state=random_state, verbosity=-1)\n",
    "\n",
    "    # Define the hyperparameter grid\n",
    "    param_grid = {\n",
    "        'max_depth': [-1],\n",
    "        'learning_rate': [0.1],\n",
    "        'n_estimators': [10]\n",
    "    }\n",
    "\n",
    "    # Setup GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=lgbm,\n",
    "        param_grid=param_grid,\n",
    "        cv=2,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Fit the grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best model from grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "\n",
    "    if return_values:\n",
    "        return y_test, y_pred\n",
    "\n",
    "    # Evaluate the model\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(\"LightGBM Regression Results:\")\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "    print(f\"Test MAE: {mae:.4f}\")\n",
    "    print(f\"Test R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3202f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features subset\n",
    "\n",
    "# 1. Nothing\n",
    "\n",
    "experiment_1_rev = []\n",
    "\n",
    "# 2. Just fundametals\n",
    "\n",
    "experiment_2_rev = [\n",
    "    \"Net Interest Income\",\n",
    "    \"Net Interest Margin\",\n",
    "    \"Net Charge-Offs\",\n",
    "    \"Cash and Short-Term Investments\",\n",
    "    \"Net Income\",\n",
    "    \"Invested Capital - Total\",\n",
    "]\n",
    "\n",
    "# 3. Just economics stuff\n",
    "\n",
    "experiment_3_rev = [\n",
    "    'GDP CHANGE (-1 to 1)', 'UNEMPLOYMENT RATE (0 to 1)',\n",
    "    'PRIME LOAN RATE (0 to 1)', 'DEPOSITS CHANGE (-1 to 1)',\n",
    "    'CONSUMER PRICE INDEX (0 to 1)', 'SAVINGS PER GROSS INCOME (-1 to 1)'\n",
    "]\n",
    "\n",
    "# 4. Just market stuff\n",
    "\n",
    "experiment_4_rev = [\n",
    "    'S&P_SMA20', 'S&P_SMA40', 'S&P_SMA60',\n",
    "    'S&P_RSI', 'TNX_SMA20', 'TNX_SMA40', 'TNX_SMA60', 'IRX_SMA20',\n",
    "    'IRX_SMA40', 'IRX_SMA60', 'FVX_SMA20', 'FVX_SMA40', 'FVX_SMA60',\n",
    "    'TYX_SMA20', 'TYX_SMA40', 'TYX_SMA60', 'DXY_SMA20', 'DXY_SMA40',\n",
    "    'DXY_SMA60', 'XLF_SMA20', 'XLF_SMA40', 'XLF_SMA60', 'XLF_RSI', 'SMA20',\n",
    "    'SMA40', 'SMA60', 'RSI', 'Volatility20', 'Volatility40', 'Volatility60'\n",
    "]\n",
    "\n",
    "# 5. Just text sentiments\n",
    "\n",
    "experiment_5_rev = [\n",
    "    'earning_calls_sentiment', 'earning_calls_confidence',\n",
    "    'earning_calls_complexity', 'news_sentiment', 'news_confidence',\n",
    "    'news_complexity_score', 'reviews_rating',\n",
    "    'text_blob_reviews_sentiment', 'vader_reviews_sentiment_neg',\n",
    "    'vader_reviews_sentiment_pos', 'bert_reviews_label',\n",
    "    'bert_reviews_score',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67d946bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 10}\n",
      "LightGBM Regression Results:\n",
      "Test RMSE: 0.0739\n",
      "Test MAE: 0.0536\n",
      "Test R²: 0.8170\n"
     ]
    }
   ],
   "source": [
    "X_rev_train, y_rev_train, X_rev_test, y_rev_test = getting_training_dataset(df_train_rev, df_test_rev, experiment_2_rev + experiment_3_rev + experiment_4_rev + experiment_5_rev)\n",
    "train_lightgbm(X_rev_train, y_rev_train, X_rev_test, y_rev_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a1f1e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just fundamentals and lagged fundametals\n",
      "Best parameters: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 10}\n",
      "LightGBM Regression Results:\n",
      "Test RMSE: 0.1368\n",
      "Test MAE: 0.0966\n",
      "Test R²: 0.3717\n"
     ]
    }
   ],
   "source": [
    "print(\"Just fundamentals and lagged fundametals\")\n",
    "X_rev_train, y_rev_train, X_rev_test, y_rev_test = getting_training_dataset(df_train_rev, df_test_rev, experiment_3_rev + experiment_4_rev + experiment_5_rev)\n",
    "train_lightgbm(X_rev_train, y_rev_train, X_rev_test, y_rev_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c4b3abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just lagged revenue and economics stuff\n",
      "Best parameters: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 10}\n",
      "LightGBM Regression Results:\n",
      "Test RMSE: 0.0743\n",
      "Test MAE: 0.0541\n",
      "Test R²: 0.8146\n"
     ]
    }
   ],
   "source": [
    "print(\"Just lagged revenue and economics stuff\")\n",
    "X_rev_train, y_rev_train, X_rev_test, y_rev_test = getting_training_dataset(df_train_rev, df_test_rev, experiment_2_rev + experiment_4_rev + experiment_5_rev)\n",
    "train_lightgbm(X_rev_train, y_rev_train, X_rev_test, y_rev_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ff1e31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just lagged revenue and market stuff\n",
      "Best parameters: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 10}\n",
      "LightGBM Regression Results:\n",
      "Test RMSE: 0.0742\n",
      "Test MAE: 0.0541\n",
      "Test R²: 0.8152\n"
     ]
    }
   ],
   "source": [
    "print(\"Just lagged revenue and market stuff\")\n",
    "X_rev_train, y_rev_train, X_rev_test, y_rev_test = getting_training_dataset(df_train_rev, df_test_rev, experiment_2_rev + experiment_3_rev + experiment_5_rev)\n",
    "train_lightgbm(X_rev_train, y_rev_train, X_rev_test, y_rev_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55fe59ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text sentiments\n",
      "Best parameters: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 10}\n",
      "LightGBM Regression Results:\n",
      "Test RMSE: 0.0739\n",
      "Test MAE: 0.0536\n",
      "Test R²: 0.8170\n"
     ]
    }
   ],
   "source": [
    "print(\"text sentiments\")\n",
    "X_rev_train, y_rev_train, X_rev_test, y_rev_test = getting_training_dataset(df_train_rev, df_test_rev, experiment_2_rev + experiment_3_rev + experiment_4_rev)\n",
    "train_lightgbm(X_rev_train, y_rev_train, X_rev_test, y_rev_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb76a73",
   "metadata": {},
   "source": [
    "## CAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3843807",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_car = pd.read_csv(\"data/train_data_CAR5_with_text.csv\")\n",
    "df_test_car = pd.read_csv(\"data/test_data_CAR5_with_text.csv\")\n",
    "df_train_car = df_train_car.sort_values(by=['tic', 'datacqtr']).reset_index(drop=True)\n",
    "df_test_car = df_test_car.sort_values(by=['tic', 'datacqtr']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05a94736",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_car = df_train_car.dropna()\n",
    "df_test_car = df_test_car.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1581c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features subset\n",
    "\n",
    "# 1. Just lagged car\n",
    "\n",
    "experiment_1_car = []\n",
    "\n",
    "# 2. Just fundamental\n",
    "\n",
    "experiment_2_car = [\n",
    "    'Net Interest Income',\n",
    "    'Net Interest Margin', 'Net Charge-Offs',\n",
    "    'Cash and Short-Term Investments', 'Net Income',\n",
    "    'Invested Capital - Total', 'Total Current Operating Revenue',\n",
    "]\n",
    "\n",
    "# 3. Just economics stuff\n",
    "\n",
    "experiment_3_car = [\n",
    "    'GDP CHANGE (-1 to 1)', 'UNEMPLOYMENT RATE (0 to 1)',\n",
    "    'PRIME LOAN RATE (0 to 1)', 'DEPOSITS CHANGE (-1 to 1)',\n",
    "    'CONSUMER PRICE INDEX (0 to 1)', 'SAVINGS PER GROSS INCOME (-1 to 1)'\n",
    "]\n",
    "\n",
    "# 4. Just market stuff\n",
    "\n",
    "experiment_4_car = [\n",
    "    'S&P_SMA5', 'S&P_SMA20', 'S&P_SMA50', 'S&P_RSI', 'VIX', 'SMA5', 'SMA20',\n",
    "    'SMA50', 'RSI', 'Volatility5', 'Volatility20', 'Volatility50',\n",
    "]\n",
    "\n",
    "# 5. Just text sentiments\n",
    "\n",
    "experiment_5_car = [\n",
    "    'earning_calls_sentiment', 'earning_calls_confidence',\n",
    "    'earning_calls_complexity', 'news_sentiment', 'news_confidence',\n",
    "    'news_complexity_score', 'reviews_rating',\n",
    "    'text_blob_reviews_sentiment', 'vader_reviews_sentiment_neg',\n",
    "    'vader_reviews_sentiment_pos', 'bert_reviews_label',\n",
    "    'bert_reviews_score',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "168f7306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 10}\n",
      "LightGBM Regression Results:\n",
      "Test RMSE: 0.0589\n",
      "Test MAE: 0.0444\n",
      "Test R²: 0.0291\n"
     ]
    }
   ],
   "source": [
    "X_car_train, y_car_train, X_car_test, y_car_test = getting_training_dataset(df_train_car, df_test_car, experiment_2_car + experiment_3_car + experiment_4_car + experiment_5_car, \"car5\")\n",
    "train_lightgbm(X_car_train, y_car_train, X_car_test, y_car_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "401b5a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 10}\n",
      "LightGBM Regression Results:\n",
      "Test RMSE: 0.0591\n",
      "Test MAE: 0.0443\n",
      "Test R²: 0.0255\n"
     ]
    }
   ],
   "source": [
    "X_car_train, y_car_train, X_car_test, y_car_test = getting_training_dataset(df_train_car, df_test_car, experiment_3_car + experiment_4_car + experiment_5_car, \"car5\")\n",
    "train_lightgbm(X_car_train, y_car_train, X_car_test, y_car_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb57374b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 10}\n",
      "LightGBM Regression Results:\n",
      "Test RMSE: 0.0582\n",
      "Test MAE: 0.0438\n",
      "Test R²: 0.0540\n"
     ]
    }
   ],
   "source": [
    "X_car_train, y_car_train, X_car_test, y_car_test = getting_training_dataset(df_train_car, df_test_car, experiment_2_car + experiment_4_car + experiment_5_car, \"car5\")\n",
    "train_lightgbm(X_car_train, y_car_train, X_car_test, y_car_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f72e533e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 10}\n",
      "LightGBM Regression Results:\n",
      "Test RMSE: 0.0614\n",
      "Test MAE: 0.0462\n",
      "Test R²: -0.0552\n"
     ]
    }
   ],
   "source": [
    "X_car_train, y_car_train, X_car_test, y_car_test = getting_training_dataset(df_train_car, df_test_car, experiment_2_car + experiment_3_car + experiment_5_car, \"car5\")\n",
    "train_lightgbm(X_car_train, y_car_train, X_car_test, y_car_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb5b8b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 10}\n",
      "LightGBM Regression Results:\n",
      "Test RMSE: 0.0591\n",
      "Test MAE: 0.0444\n",
      "Test R²: 0.0237\n"
     ]
    }
   ],
   "source": [
    "X_car_train, y_car_train, X_car_test, y_car_test = getting_training_dataset(df_train_car, df_test_car, experiment_2_car + experiment_3_car + experiment_4_car, \"car5\")\n",
    "train_lightgbm(X_car_train, y_car_train, X_car_test, y_car_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617f652d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
