{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36b25f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "from typing import List, Dict, Tuple, Union, Optional\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Create directory for models if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2fbd64a-aa8f-4942-84f4-0d9a2f42571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9fa04d9-9ed9-4016-b3a7-c7af8d249c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stacking_data() -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load the stacking data from CSV files prepared by team members\n",
    "    \n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "        - Revenue training data\n",
    "        - CAR training data\n",
    "        - Revenue test data\n",
    "        - CAR test data\n",
    "    \"\"\"\n",
    "    # Load Revenue prediction models - Training data\n",
    "    light_gbm_rev = pd.read_csv(\"data/stacking_data/lightgbm_rev_predict.csv\")\n",
    "    neural_network_rev = pd.read_csv(\"data/stacking_data/neural_network_rev_predict.csv\")\n",
    "    ridge_reg_rev = pd.read_csv(\"data/stacking_data/ridge_regression_rev_predict.csv\")\n",
    "    rev_truth = pd.read_csv(\"data/train_data_REV_with_text.csv\")[[\"tic\", \"datacqtr\", \"Total Current Operating Revenue\"]]\n",
    "    \n",
    "    # Merge revenue training data\n",
    "    df_rev_train = light_gbm_rev.merge(neural_network_rev, on=[\"tic\", \"datacqtr\"], how=\"left\")\n",
    "    df_rev_train = df_rev_train.merge(ridge_reg_rev, on=[\"tic\", \"datacqtr\"], how=\"left\")\n",
    "    df_rev_train = df_rev_train.merge(rev_truth, on=[\"tic\", \"datacqtr\"], how=\"left\")\n",
    "\n",
    "    # Load CAR prediction models - Training data\n",
    "    random_forest_car = pd.read_csv(\"data/stacking_data/random_forest_car_predict.csv\")\n",
    "    neural_network_car = pd.read_csv(\"data/stacking_data/neural_network_car_predict.csv\")\n",
    "    lasso_reg_car = pd.read_csv(\"data/stacking_data/lasso_regression_car_predict.csv\")\n",
    "    car_truth = pd.read_csv(\"data/train_data_CAR5_with_text.csv\")[[\"tic\", \"datacqtr\", \"car5\"]]\n",
    "    \n",
    "    # Merge CAR training data\n",
    "    # For now, we only have neural network predictions for CAR\n",
    "    df_car_train = neural_network_car.copy()  # random_forest_car[[\"tic\", \"datacqtr\"]].copy() # neural_network_car.copy()\n",
    "    df_car_train = df_car_train.merge(random_forest_car, on=[\"tic\", \"datacqtr\"], how=\"left\")\n",
    "    df_car_train = df_car_train.merge(lasso_reg_car, on=[\"tic\", \"datacqtr\"], how=\"left\")\n",
    "    df_car_train = df_car_train.merge(car_truth, on=[\"tic\", \"datacqtr\"], how=\"left\")\n",
    "    \n",
    "    # Load Revenue prediction models - Test data\n",
    "    light_gbm_rev_test = pd.read_csv(\"data/results/lightgbm_rev_predict_test.csv\")\n",
    "    neural_network_rev_test = pd.read_csv(\"data/results/neural_network_rev_predict_test.csv\")\n",
    "    ridge_reg_rev_test = pd.read_csv(\"data/results/ridge_regression_rev_predict_test.csv\")\n",
    "    rev_truth_test = pd.read_csv(\"data/test_data_REV_with_text.csv\")[[\"tic\", \"datacqtr\", \"Total Current Operating Revenue\"]]\n",
    "    \n",
    "    # Merge revenue test data\n",
    "    df_rev_test = light_gbm_rev_test.merge(neural_network_rev_test, on=[\"tic\", \"datacqtr\"], how=\"left\")\n",
    "    df_rev_test = df_rev_test.merge(ridge_reg_rev_test, on=[\"tic\", \"datacqtr\"], how=\"left\")\n",
    "    df_rev_test = df_rev_test.merge(rev_truth_test, on=[\"tic\", \"datacqtr\"], how=\"left\")\n",
    "    \n",
    "    # Load CAR prediction models - Test data\n",
    "    random_forest_car_test = pd.read_csv(\"data/results/random_forest_car_predict_test.csv\")\n",
    "    neural_network_car_test = pd.read_csv(\"data/results/neural_network_car_predict_test.csv\")\n",
    "    lasso_reg_car_test = pd.read_csv(\"data/results/lasso_regression_car_predict_test.csv\")\n",
    "    car_truth_test = pd.read_csv(\"data/test_data_CAR5_with_text.csv\")[[\"tic\", \"datacqtr\", \"car5\"]]\n",
    "    \n",
    "    # Merge CAR test data\n",
    "    # For now, we only have neural network predictions for CAR\n",
    "    df_car_test = neural_network_car_test.copy()  # random_forest_car_test[[\"tic\", \"datacqtr\"]].copy() # neural_network_car_test.copy()\n",
    "    df_car_test = df_car_test.merge(random_forest_car_test, on=[\"tic\", \"datacqtr\"], how=\"left\")\n",
    "    df_car_test = df_car_test.merge(lasso_reg_car_test, on=[\"tic\", \"datacqtr\"], how=\"left\")\n",
    "    df_car_test = df_car_test.merge(car_truth_test, on=[\"tic\", \"datacqtr\"], how=\"left\")\n",
    "    \n",
    "    # Drop all nans\n",
    "    df_rev_train = df_rev_train.dropna().reset_index(drop=True).copy()\n",
    "    df_car_train = df_car_train.dropna().reset_index(drop=True).copy()\n",
    "    df_rev_test = df_rev_test.dropna().reset_index(drop=True).copy()\n",
    "    df_car_test = df_car_test.dropna().reset_index(drop=True).copy()\n",
    "\n",
    "    # Print some basic information about the data\n",
    "    print(f\"Revenue training data shape: {df_rev_train.shape}\")\n",
    "    print(f\"CAR training data shape: {df_car_train.shape}\")\n",
    "    print(f\"Revenue test data shape: {df_rev_test.shape}\")\n",
    "    print(f\"CAR test data shape: {df_car_test.shape}\")\n",
    "\n",
    "    \n",
    "    return df_rev_train, df_car_train, df_rev_test, df_car_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55ff6ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue training data shape: (7276, 6)\n",
      "CAR training data shape: (7874, 6)\n",
      "Revenue test data shape: (1021, 6)\n",
      "CAR test data shape: (1378, 6)\n"
     ]
    }
   ],
   "source": [
    "df_rev_train, df_car_train, df_rev_test, df_car_test = load_stacking_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea8fb2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_for_stacking(\n",
    "    df: pd.DataFrame, \n",
    "    target_column: str,\n",
    "    id_columns: List[str] = ['tic', 'datacqtr']\n",
    ") -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Prepare features for stacking model\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame with predictions from base models\n",
    "        target_column: Name of the target column (actual values)\n",
    "        id_columns: List of identifier columns to exclude from features\n",
    "        \n",
    "    Returns:\n",
    "        X and y for training\n",
    "    \"\"\"\n",
    "    # Filter columns that contain predictions (feature columns)\n",
    "    feature_columns = [\n",
    "        col for col in df.columns \n",
    "        if col not in id_columns and col != target_column\n",
    "    ]\n",
    "    \n",
    "    # Create feature matrix\n",
    "    X = df[feature_columns].copy()\n",
    "    \n",
    "    # Create target vector\n",
    "    y = df[target_column].copy()\n",
    "    \n",
    "    print(f\"Features for stacking: {feature_columns}\")\n",
    "    print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def create_time_based_validation(\n",
    "    df: pd.DataFrame, \n",
    "    time_column: str = 'datacqtr',\n",
    "    n_splits: int = 3\n",
    ") -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Create time-based cross-validation splits based on quarter/year\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to split\n",
    "        time_column: Column containing time information (datacqtr)\n",
    "        n_splits: Number of splits\n",
    "        \n",
    "    Returns:\n",
    "        List of train and validation indices\n",
    "    \"\"\"\n",
    "    # Extract year and quarter from datacqtr (format: YYYYQN)\n",
    "    df['year'] = df[time_column].str.extract(r'(\\d{4})').astype(int)\n",
    "    df['quarter'] = df[time_column].str.extract(r'Q(\\d)').astype(int)\n",
    "    \n",
    "    # Create a numerical time_id for sorting\n",
    "    df['time_id'] = df['year'] * 4 + df['quarter']\n",
    "    \n",
    "    # Sort by time\n",
    "    df = df.sort_values('time_id')\n",
    "    \n",
    "    # Create time-based splits\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    splits = []\n",
    "    \n",
    "    for train_idx, val_idx in tscv.split(df):\n",
    "        splits.append((train_idx, val_idx))\n",
    "    \n",
    "    return splits\n",
    "\n",
    "\n",
    "def stacking_pipeline() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Run the full stacking pipeline with models suggested by the team:\n",
    "    - Simple linear model for revenue (to avoid overfitting)\n",
    "    - More complex model like Random Forest for CAR\n",
    "    - Focus on R², MSE and MAE metrics\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of two DataFrames:\n",
    "        - Revenue predictions\n",
    "        - CAR predictions\n",
    "    \"\"\"\n",
    "    # Load stacking data\n",
    "    df_rev_train, df_car_train, df_rev_test, df_car_test = load_stacking_data()\n",
    "    \n",
    "    # Create time-based CV splits - do this once and reuse\n",
    "    cv_splits_rev = create_time_based_validation(df_rev_train)\n",
    "    cv_splits_car = create_time_based_validation(df_car_train)\n",
    "    \n",
    "    # Revenue Stacking - Use simple model (linear regression) as recommended\n",
    "    print(\"\\n=== Revenue Stacking ===\")\n",
    "    \n",
    "    # Prepare features for revenue prediction - Only use the model prediction columns\n",
    "    # Extract just the prediction columns (not the time columns)\n",
    "    rev_feature_cols = [col for col in df_rev_train.columns if '_predict' in col]\n",
    "    print(f\"Using only these features for revenue stacking: {rev_feature_cols}\")\n",
    "    \n",
    "    X_rev = df_rev_train[rev_feature_cols].copy()\n",
    "    y_rev = df_rev_train['Total Current Operating Revenue']\n",
    "    X_rev_test = df_rev_test[rev_feature_cols].copy()\n",
    "    \n",
    "    print(f\"X_rev shape: {X_rev.shape}, y_rev shape: {y_rev.shape}\")\n",
    "    print(f\"X_rev_test shape: {X_rev_test.shape}\")\n",
    "    \n",
    "    # Use Ridge regression (a regularized linear model) for revenue to avoid overfitting\n",
    "    print(\"Training Linear Model (Ridge) for Revenue stacking...\")\n",
    "    scaler_rev = StandardScaler()\n",
    "    X_rev_scaled = scaler_rev.fit_transform(X_rev)\n",
    "    X_rev_test_scaled = scaler_rev.transform(X_rev_test)\n",
    "    \n",
    "    linear_model_rev = Ridge(alpha=1.0, random_state=42)\n",
    "    \n",
    "    # Evaluate with cross-validation\n",
    "    val_scores_r2 = []\n",
    "    val_scores_mse = []\n",
    "    val_scores_mae = []\n",
    "    \n",
    "    for i, (train_idx, val_idx) in enumerate(cv_splits_rev):\n",
    "        X_train, y_train = X_rev_scaled[train_idx], y_rev.iloc[train_idx]\n",
    "        X_val, y_val = X_rev_scaled[val_idx], y_rev.iloc[val_idx]\n",
    "        \n",
    "        # Train model\n",
    "        linear_model_rev.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        val_preds = linear_model_rev.predict(X_val)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        r2 = r2_score(y_val, val_preds)\n",
    "        mse = mean_squared_error(y_val, val_preds)\n",
    "        mae = np.mean(np.abs(y_val - val_preds))\n",
    "        \n",
    "        val_scores_r2.append(r2)\n",
    "        val_scores_mse.append(mse)\n",
    "        val_scores_mae.append(mae)\n",
    "        \n",
    "        print(f\"Fold {i+1}/{len(cv_splits_rev)}: R² = {r2:.4f}, MSE = {mse:.4f}, MAE = {mae:.4f}\")\n",
    "    \n",
    "    # Calculate average validation scores\n",
    "    avg_r2 = np.mean(val_scores_r2)\n",
    "    avg_mse = np.mean(val_scores_mse)\n",
    "    avg_mae = np.mean(val_scores_mae)\n",
    "    \n",
    "    print(f\"Average metrics for Revenue model: R² = {avg_r2:.4f}, MSE = {avg_mse:.4f}, MAE = {avg_mae:.4f}\")\n",
    "    \n",
    "    # Re-fit on all training data\n",
    "    linear_model_rev.fit(X_rev_scaled, y_rev)\n",
    "    \n",
    "    # Save the model\n",
    "    joblib.dump((linear_model_rev, scaler_rev), 'models/stacking_linear_revenue.pkl')\n",
    "    \n",
    "    # Generate revenue predictions for test data\n",
    "    revenue_results = df_rev_test[['tic', 'datacqtr']].copy()\n",
    "    revenue_results['revenue_prediction'] = linear_model_rev.predict(X_rev_test_scaled)\n",
    "    \n",
    "    # CAR Stacking - Use more complex model (Random Forest) as recommended\n",
    "    print(\"\\n=== CAR Stacking ===\")\n",
    "    \n",
    "    # Prepare features for CAR prediction - Only use the model prediction columns\n",
    "    car_feature_cols = [col for col in df_car_train.columns if '_predict' in col]\n",
    "    print(f\"Using only these features for CAR stacking: {car_feature_cols}\")\n",
    "    \n",
    "    X_car = df_car_train[car_feature_cols].copy()\n",
    "    y_car = df_car_train['car5']\n",
    "    X_car_test = df_car_test[car_feature_cols].copy()\n",
    "    \n",
    "    print(f\"X_car shape: {X_car.shape}, y_car shape: {y_car.shape}\")\n",
    "    print(f\"X_car_test shape: {X_car_test.shape}\")\n",
    "    \n",
    "    # Use Random Forest for CAR as recommended\n",
    "    print(\"Training Random Forest for CAR stacking...\")\n",
    "    # model_car = RandomForestRegressor(\n",
    "    #     n_estimators=100, \n",
    "    #     max_depth=5,\n",
    "    #     min_samples_split=5,\n",
    "    #     min_samples_leaf=2,\n",
    "    #     random_state=42\n",
    "    # )\n",
    "    model_car = lgb.LGBMRegressor(\n",
    "        n_estimators=10,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42,\n",
    "        verbosity=-1\n",
    "    )\n",
    "    # model_car = XGBRegressor(\n",
    "    #     n_estimators=10,\n",
    "    #     learning_rate=0.05,\n",
    "    #     random_state=42,\n",
    "    #     n_jobs=-1,\n",
    "    #     verbosity=0\n",
    "    # )\n",
    "    \n",
    "    # Evaluate with cross-validation\n",
    "    val_scores_r2 = []\n",
    "    val_scores_mse = []\n",
    "    val_scores_mae = []\n",
    "    \n",
    "    for i, (train_idx, val_idx) in enumerate(cv_splits_car):\n",
    "        X_train, y_train = X_car.iloc[train_idx], y_car.iloc[train_idx]\n",
    "        X_val, y_val = X_car.iloc[val_idx], y_car.iloc[val_idx]\n",
    "        \n",
    "        # Train model\n",
    "        model_car.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        val_preds = model_car.predict(X_val)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        r2 = r2_score(y_val, val_preds)\n",
    "        mse = mean_squared_error(y_val, val_preds)\n",
    "        mae = np.mean(np.abs(y_val - val_preds))\n",
    "        \n",
    "        val_scores_r2.append(r2)\n",
    "        val_scores_mse.append(mse)\n",
    "        val_scores_mae.append(mae)\n",
    "        \n",
    "        print(f\"Fold {i+1}/{len(cv_splits_car)}: R² = {r2:.4f}, MSE = {mse:.4f}, MAE = {mae:.4f}\")\n",
    "    \n",
    "    # Calculate average validation scores\n",
    "    avg_r2 = np.mean(val_scores_r2)\n",
    "    avg_mse = np.mean(val_scores_mse)\n",
    "    avg_mae = np.mean(val_scores_mae)\n",
    "    \n",
    "    print(f\"Average metrics for CAR model: R² = {avg_r2:.4f}, MSE = {avg_mse:.4f}, MAE = {avg_mae:.4f}\")\n",
    "    \n",
    "    # Re-fit on all training data\n",
    "    model_car.fit(X_car, y_car)\n",
    "    \n",
    "    # Save the model\n",
    "    joblib.dump(model_car, 'models/stacking_randomforest_car.pkl')\n",
    "    \n",
    "    # Generate CAR predictions for test data\n",
    "    car_results = df_car_test[['tic', 'datacqtr']].copy()\n",
    "    car_results['car_prediction'] = model_car.predict(X_car_test)\n",
    "    \n",
    "    # Return both DataFrames with predictions\n",
    "    return revenue_results, car_results\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the stacking pipeline\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Run the stacking pipeline - now returns two separate DataFrames\n",
    "        revenue_predictions, car_predictions = stacking_pipeline()\n",
    "        \n",
    "        # Save the predictions to separate files\n",
    "        revenue_predictions.to_csv('stacking_revenue_predictions.csv', index=False)\n",
    "        car_predictions.to_csv('stacking_car_predictions.csv', index=False)\n",
    "        \n",
    "        print(\"\\nStacking pipeline completed successfully!\")\n",
    "        print(\"Revenue predictions saved to 'stacking_revenue_predictions.csv'\")\n",
    "        print(\"CAR predictions saved to 'stacking_car_predictions.csv'\")\n",
    "        \n",
    "        # Try to merge predictions if tic and datacqtr match (without forcing)\n",
    "        print(\"\\nAttempting to merge predictions for common tic/datacqtr pairs...\")\n",
    "        merged_predictions = revenue_predictions.merge(\n",
    "            car_predictions, \n",
    "            on=['tic', 'datacqtr'], \n",
    "            how='inner',\n",
    "            suffixes=('', '_car')\n",
    "        )\n",
    "        \n",
    "        if len(merged_predictions) > 0:\n",
    "            merged_predictions.to_csv('stacking_merged_predictions.csv', index=False)\n",
    "            print(f\"Successfully merged {len(merged_predictions)} matching predictions saved to 'stacking_merged_predictions.csv'\")\n",
    "            print(\"\\nSample merged predictions:\")\n",
    "            print(merged_predictions.head(5))\n",
    "        else:\n",
    "            print(\"No matching tic/datacqtr pairs found between revenue and CAR predictions.\")\n",
    "        \n",
    "        # Display samples of individual predictions\n",
    "        print(\"\\nSample revenue predictions:\")\n",
    "        print(revenue_predictions.head(5))\n",
    "        print(\"\\nSample CAR predictions:\")\n",
    "        print(car_predictions.head(5))\n",
    "        \n",
    "        return revenue_predictions, car_predictions, merged_predictions if len(merged_predictions) > 0 else None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ff28c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue training data shape: (7276, 6)\n",
      "CAR training data shape: (7874, 6)\n",
      "Revenue test data shape: (1021, 6)\n",
      "CAR test data shape: (1378, 6)\n",
      "\n",
      "=== Revenue Stacking ===\n",
      "Using only these features for revenue stacking: ['light_gbm_rev_predict', 'neural_network_rev_predict', 'ridge_reg_rev_predict']\n",
      "X_rev shape: (7276, 3), y_rev shape: (7276,)\n",
      "X_rev_test shape: (1021, 3)\n",
      "Training Linear Model (Ridge) for Revenue stacking...\n",
      "Fold 1/3: R² = 0.9959, MSE = 0.0001, MAE = 0.0055\n",
      "Fold 2/3: R² = 0.9922, MSE = 0.0002, MAE = 0.0058\n",
      "Fold 3/3: R² = 0.9978, MSE = 0.0001, MAE = 0.0047\n",
      "Average metrics for Revenue model: R² = 0.9953, MSE = 0.0001, MAE = 0.0053\n",
      "\n",
      "=== CAR Stacking ===\n",
      "Using only these features for CAR stacking: ['neural_network_car_predict', 'randomforest_car_predict', 'lasso_car_predict']\n",
      "X_car shape: (7874, 3), y_car shape: (7874,)\n",
      "X_car_test shape: (1378, 3)\n",
      "Training Random Forest for CAR stacking...\n",
      "Fold 1/3: R² = 0.0891, MSE = 0.0030, MAE = 0.0398\n",
      "Fold 2/3: R² = 0.0740, MSE = 0.0031, MAE = 0.0404\n",
      "Fold 3/3: R² = 0.0882, MSE = 0.0029, MAE = 0.0390\n",
      "Average metrics for CAR model: R² = 0.0838, MSE = 0.0030, MAE = 0.0397\n",
      "\n",
      "Stacking pipeline completed successfully!\n",
      "Revenue predictions saved to 'stacking_revenue_predictions.csv'\n",
      "CAR predictions saved to 'stacking_car_predictions.csv'\n",
      "\n",
      "Attempting to merge predictions for common tic/datacqtr pairs...\n",
      "Successfully merged 1012 matching predictions saved to 'stacking_merged_predictions.csv'\n",
      "\n",
      "Sample merged predictions:\n",
      "    tic datacqtr  revenue_prediction  car_prediction\n",
      "0  ALRS   2022Q1            0.376747        0.009206\n",
      "1  AMAL   2022Q1            0.368448        0.009206\n",
      "2  AMNB   2022Q1            0.326002        0.009206\n",
      "3  AMTB   2022Q1            0.450132        0.005868\n",
      "4  AROW   2022Q1            0.347771        0.009206\n",
      "\n",
      "Sample revenue predictions:\n",
      "    tic datacqtr  revenue_prediction\n",
      "0  ALRS   2022Q1            0.376747\n",
      "1  AMAL   2022Q1            0.368448\n",
      "2  AMNB   2022Q1            0.326002\n",
      "3  AMTB   2022Q1            0.450132\n",
      "4  AROW   2022Q1            0.347771\n",
      "\n",
      "Sample CAR predictions:\n",
      "    tic datacqtr  car_prediction\n",
      "0  ALRS   2021Q2       -0.002707\n",
      "1  ALRS   2021Q3        0.003154\n",
      "2  ALRS   2021Q4        0.003231\n",
      "3  ALRS   2022Q1        0.009206\n",
      "4  ALRS   2022Q2        0.009206\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Run the main pipeline\n",
    "    final_predictions = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45885b1",
   "metadata": {},
   "source": [
    "## Test Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a978e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d16f0073",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_predictions, car_predictions, _ = final_predictions\n",
    "revenue_predictions = revenue_predictions.merge(df_rev_test[[\"tic\", \"datacqtr\", \"Total Current Operating Revenue\"]], on=[\"tic\", \"datacqtr\"], how=\"left\")\n",
    "car_predictions = car_predictions.merge(df_car_test[[\"tic\", \"datacqtr\", \"car5\"]], on=[\"tic\", \"datacqtr\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2a9206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(df):\n",
    "    y_true = df[df.columns[0]]\n",
    "    y_pred = df[df.columns[1]]\n",
    "    \n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'R2': r2,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7680637b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue Stacking Results\n",
      "{'R2': 0.9954720232441281, 'MSE': 0.000136218275765789, 'MAE': 0.0072136945946598505}\n",
      "##########\n",
      "CAR Stacking Results\n",
      "{'R2': 0.038618423069640695, 'MSE': 0.0033984112528089826, 'MAE': 0.04364910291661797}\n"
     ]
    }
   ],
   "source": [
    "print(\"Revenue Stacking Results\")\n",
    "print(evaluate_predictions(revenue_predictions[[\"Total Current Operating Revenue\", \"revenue_prediction\"]]))\n",
    "print(\"#\"*10)\n",
    "print(\"CAR Stacking Results\")\n",
    "print(evaluate_predictions(car_predictions[[\"car5\", \"car_prediction\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37f5eb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue Individual Results\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "LightGBM\n",
      "{'R2': 0.9948997611836082, 'MSE': 0.00015343403356955977, 'MAE': 0.00772067223945381}\n",
      "##################################################\n",
      "NN\n",
      "{'R2': 0.9856291907575117, 'MSE': 0.0004323270550875175, 'MAE': 0.015346523060197145}\n",
      "##################################################\n",
      "Ridge\n",
      "{'R2': 0.9809860270038102, 'MSE': 0.0005720105814676431, 'MAE': 0.01845830990227891}\n"
     ]
    }
   ],
   "source": [
    "print(\"Revenue Individual Results\")\n",
    "print(\"-\"*50)\n",
    "print(\"-\"*50)\n",
    "print(\"LightGBM\")\n",
    "print(evaluate_predictions(df_rev_test[[\"Total Current Operating Revenue\", \"light_gbm_rev_predict\"]]))\n",
    "print(\"#\"*50)\n",
    "print(\"NN\")\n",
    "print(evaluate_predictions(df_rev_test[[\"Total Current Operating Revenue\", \"neural_network_rev_predict\"]]))\n",
    "print(\"#\"*50)\n",
    "print(\"Ridge\")\n",
    "print(evaluate_predictions(df_rev_test[[\"Total Current Operating Revenue\", \"ridge_reg_rev_predict\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "514b6dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car Individual Results\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "NN\n",
      "{'R2': -0.048427735265690997, 'MSE': 0.0037061128471593935, 'MAE': 0.0458951758386484}\n",
      "##################################################\n",
      "Lasso regression\n",
      "{'R2': -0.0019309169371346524, 'MSE': 0.0035417501066832184, 'MAE': 0.044548439085482776}\n",
      "##################################################\n",
      "Random Forest\n",
      "{'R2': 0.05391663074399877, 'MSE': 0.003344333244288841, 'MAE': 0.04340659723010807}\n"
     ]
    }
   ],
   "source": [
    "print(\"Car Individual Results\")\n",
    "print(\"-\"*50)\n",
    "print(\"-\"*50)\n",
    "print(\"NN\")\n",
    "print(evaluate_predictions(df_car_test[[\"car5\", \"neural_network_car_predict\"]]))\n",
    "print(\"#\"*50)\n",
    "print(\"Lasso regression\")\n",
    "print(evaluate_predictions(df_car_test[[\"car5\", \"lasso_car_predict\"]]))\n",
    "print(\"#\"*50)\n",
    "print(\"Random Forest\")\n",
    "print(evaluate_predictions(df_car_test[[\"car5\", \"randomforest_car_predict\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348fc5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bcfb99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
