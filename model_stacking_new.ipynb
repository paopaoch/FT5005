{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fa04d9-9ed9-4016-b3a7-c7af8d249c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "from typing import List, Dict, Tuple, Union, Optional\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Create directory for models if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "\n",
    "def load_stacking_data() -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load the stacking data from CSV files prepared by team members\n",
    "    \n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "        - Revenue training data\n",
    "        - CAR training data\n",
    "        - Revenue test data\n",
    "        - CAR test data\n",
    "    \"\"\"\n",
    "    # Load Revenue prediction models - Training data\n",
    "    light_gbm_rev = pd.read_csv(\"data/stacking_data/lightgbm_rev_predict.csv\")\n",
    "    neural_network_rev = pd.read_csv(\"data/stacking_data/neural_network_rev_predict.csv\")\n",
    "    # ridge_reg_rev = pd.read_csv(\"data/stacking_data/ridge_regression_rev_predict.csv\")  # Not ready yet!\n",
    "    rev_truth = pd.read_csv(\"data/train_data_REV_with_text.csv\")[[\"tic\", \"datacqtr\", \"Total Current Operating Revenue\"]]\n",
    "    \n",
    "    # Merge revenue training data\n",
    "    df_rev_train = light_gbm_rev.merge(neural_network_rev, on=[\"tic\", \"datacqtr\"], how=\"left\")\n",
    "    # df_rev_train = df_rev_train.merge(ridge_reg_rev, on=[\"tic\", \"datacqtr\"], how=\"left\")  # Uncomment when ready\n",
    "    df_rev_train = df_rev_train.merge(rev_truth, on=[\"tic\", \"datacqtr\"], how=\"left\")\n",
    "\n",
    "    # Load CAR prediction models - Training data\n",
    "    # random_forest_car = pd.read_csv(\"data/stacking_data/random_forest_car_predict.csv\")  # Not ready yet\n",
    "    neural_network_car = pd.read_csv(\"data/stacking_data/neural_network_car_predict.csv\")\n",
    "    # lasso_reg_car = pd.read_csv(\"data/stacking_data/lasso_regression_car_predict.csv\")  # Not ready yet!\n",
    "    car_truth = pd.read_csv(\"data/train_data_CAR5_with_text.csv\")[[\"tic\", \"datacqtr\", \"car5\"]]\n",
    "    \n",
    "    # Merge CAR training data\n",
    "    # For now, we only have neural network predictions for CAR\n",
    "    df_car_train = neural_network_car.copy()\n",
    "    # df_car_train = neural_network_car.merge(random_forest_car, on=[\"tic\", \"datacqtr\"], how=\"left\")  # Uncomment when ready\n",
    "    # df_car_train = df_car_train.merge(lasso_reg_car, on=[\"tic\", \"datacqtr\"], how=\"left\")  # Uncomment when ready\n",
    "    df_car_train = df_car_train.merge(car_truth, on=[\"tic\", \"datacqtr\"], how=\"left\")\n",
    "    \n",
    "    # Load Revenue prediction models - Test data\n",
    "    light_gbm_rev_test = pd.read_csv(\"data/results/lightgbm_rev_predict_test.csv\")\n",
    "    neural_network_rev_test = pd.read_csv(\"data/results/neural_network_rev_predict_test.csv\")\n",
    "    # ridge_reg_rev_test = pd.read_csv(\"data/results/ridge_regression_rev_predict_test.csv\")  # Not ready yet!\n",
    "    rev_truth_test = pd.read_csv(\"data/test_data_REV_with_text.csv\")[[\"tic\", \"datacqtr\", \"Total Current Operating Revenue\"]]\n",
    "    \n",
    "    # Merge revenue test data\n",
    "    df_rev_test = light_gbm_rev_test.merge(neural_network_rev_test, on=[\"tic\", \"datacqtr\"], how=\"left\")\n",
    "    # df_rev_test = df_rev_test.merge(ridge_reg_rev_test, on=[\"tic\", \"datacqtr\"], how=\"left\")  # Uncomment when ready\n",
    "    df_rev_test = df_rev_test.merge(rev_truth_test, on=[\"tic\", \"datacqtr\"], how=\"left\")\n",
    "    \n",
    "    # Load CAR prediction models - Test data\n",
    "    # random_forest_car_test = pd.read_csv(\"data/results/random_forest_car_predict_test.csv\")  # Not ready yet\n",
    "    neural_network_car_test = pd.read_csv(\"data/results/neural_network_car_predict_test.csv\")\n",
    "    # lasso_reg_car_test = pd.read_csv(\"data/results/lasso_regression_car_predict_test.csv\")  # Not ready yet!\n",
    "    car_truth_test = pd.read_csv(\"data/test_data_CAR5_with_text.csv\")[[\"tic\", \"datacqtr\", \"car5\"]]\n",
    "    \n",
    "    # Merge CAR test data\n",
    "    # For now, we only have neural network predictions for CAR\n",
    "    df_car_test = neural_network_car_test.copy()\n",
    "    # df_car_test = neural_network_car_test.merge(random_forest_car_test, on=[\"tic\", \"datacqtr\"], how=\"left\")  # Uncomment when ready\n",
    "    # df_car_test = df_car_test.merge(lasso_reg_car_test, on=[\"tic\", \"datacqtr\"], how=\"left\")  # Uncomment when ready\n",
    "    df_car_test = df_car_test.merge(car_truth_test, on=[\"tic\", \"datacqtr\"], how=\"left\")\n",
    "    \n",
    "    # Print some basic information about the data\n",
    "    print(f\"Revenue training data shape: {df_rev_train.shape}\")\n",
    "    print(f\"CAR training data shape: {df_car_train.shape}\")\n",
    "    print(f\"Revenue test data shape: {df_rev_test.shape}\")\n",
    "    print(f\"CAR test data shape: {df_car_test.shape}\")\n",
    "    \n",
    "    return df_rev_train, df_car_train, df_rev_test, df_car_test\n",
    "\n",
    "\n",
    "def prepare_features_for_stacking(\n",
    "    df: pd.DataFrame, \n",
    "    target_column: str,\n",
    "    id_columns: List[str] = ['tic', 'datacqtr']\n",
    ") -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Prepare features for stacking model\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame with predictions from base models\n",
    "        target_column: Name of the target column (actual values)\n",
    "        id_columns: List of identifier columns to exclude from features\n",
    "        \n",
    "    Returns:\n",
    "        X and y for training\n",
    "    \"\"\"\n",
    "    # Filter columns that contain predictions (feature columns)\n",
    "    feature_columns = [\n",
    "        col for col in df.columns \n",
    "        if col not in id_columns and col != target_column\n",
    "    ]\n",
    "    \n",
    "    # Create feature matrix\n",
    "    X = df[feature_columns].copy()\n",
    "    \n",
    "    # Create target vector\n",
    "    y = df[target_column].copy()\n",
    "    \n",
    "    print(f\"Features for stacking: {feature_columns}\")\n",
    "    print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def create_time_based_validation(\n",
    "    df: pd.DataFrame, \n",
    "    time_column: str = 'datacqtr',\n",
    "    n_splits: int = 3\n",
    ") -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Create time-based cross-validation splits based on quarter/year\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to split\n",
    "        time_column: Column containing time information (datacqtr)\n",
    "        n_splits: Number of splits\n",
    "        \n",
    "    Returns:\n",
    "        List of train and validation indices\n",
    "    \"\"\"\n",
    "    # Extract year and quarter from datacqtr (format: YYYYQN)\n",
    "    df['year'] = df[time_column].str.extract(r'(\\d{4})').astype(int)\n",
    "    df['quarter'] = df[time_column].str.extract(r'Q(\\d)').astype(int)\n",
    "    \n",
    "    # Create a numerical time_id for sorting\n",
    "    df['time_id'] = df['year'] * 4 + df['quarter']\n",
    "    \n",
    "    # Sort by time\n",
    "    df = df.sort_values('time_id')\n",
    "    \n",
    "    # Create time-based splits\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    splits = []\n",
    "    \n",
    "    for train_idx, val_idx in tscv.split(df):\n",
    "        splits.append((train_idx, val_idx))\n",
    "    \n",
    "    return splits\n",
    "\n",
    "\n",
    "def stacking_pipeline() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Run the full stacking pipeline with models suggested by the team:\n",
    "    - Simple linear model for revenue (to avoid overfitting)\n",
    "    - More complex model like Random Forest for CAR\n",
    "    - Focus on RÂ², MSE and MAE metrics\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of two DataFrames:\n",
    "        - Revenue predictions\n",
    "        - CAR predictions\n",
    "    \"\"\"\n",
    "    # Load stacking data\n",
    "    df_rev_train, df_car_train, df_rev_test, df_car_test = load_stacking_data()\n",
    "    \n",
    "    # Create time-based CV splits - do this once and reuse\n",
    "    cv_splits_rev = create_time_based_validation(df_rev_train)\n",
    "    cv_splits_car = create_time_based_validation(df_car_train)\n",
    "    \n",
    "    # Revenue Stacking - Use simple model (linear regression) as recommended\n",
    "    print(\"\\n=== Revenue Stacking ===\")\n",
    "    \n",
    "    # Prepare features for revenue prediction - Only use the model prediction columns\n",
    "    # Extract just the prediction columns (not the time columns)\n",
    "    rev_feature_cols = [col for col in df_rev_train.columns if '_predict' in col]\n",
    "    print(f\"Using only these features for revenue stacking: {rev_feature_cols}\")\n",
    "    \n",
    "    X_rev = df_rev_train[rev_feature_cols].copy()\n",
    "    y_rev = df_rev_train['Total Current Operating Revenue']\n",
    "    X_rev_test = df_rev_test[rev_feature_cols].copy()\n",
    "    \n",
    "    print(f\"X_rev shape: {X_rev.shape}, y_rev shape: {y_rev.shape}\")\n",
    "    print(f\"X_rev_test shape: {X_rev_test.shape}\")\n",
    "    \n",
    "    # Use Ridge regression (a regularized linear model) for revenue to avoid overfitting\n",
    "    print(\"Training Linear Model (Ridge) for Revenue stacking...\")\n",
    "    scaler_rev = StandardScaler()\n",
    "    X_rev_scaled = scaler_rev.fit_transform(X_rev)\n",
    "    X_rev_test_scaled = scaler_rev.transform(X_rev_test)\n",
    "    \n",
    "    linear_model_rev = Ridge(alpha=1.0, random_state=42)\n",
    "    \n",
    "    # Evaluate with cross-validation\n",
    "    val_scores_r2 = []\n",
    "    val_scores_mse = []\n",
    "    val_scores_mae = []\n",
    "    \n",
    "    for i, (train_idx, val_idx) in enumerate(cv_splits_rev):\n",
    "        X_train, y_train = X_rev_scaled[train_idx], y_rev.iloc[train_idx]\n",
    "        X_val, y_val = X_rev_scaled[val_idx], y_rev.iloc[val_idx]\n",
    "        \n",
    "        # Train model\n",
    "        linear_model_rev.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        val_preds = linear_model_rev.predict(X_val)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        r2 = r2_score(y_val, val_preds)\n",
    "        mse = mean_squared_error(y_val, val_preds)\n",
    "        mae = np.mean(np.abs(y_val - val_preds))\n",
    "        \n",
    "        val_scores_r2.append(r2)\n",
    "        val_scores_mse.append(mse)\n",
    "        val_scores_mae.append(mae)\n",
    "        \n",
    "        print(f\"Fold {i+1}/{len(cv_splits_rev)}: RÂ² = {r2:.4f}, MSE = {mse:.4f}, MAE = {mae:.4f}\")\n",
    "    \n",
    "    # Calculate average validation scores\n",
    "    avg_r2 = np.mean(val_scores_r2)\n",
    "    avg_mse = np.mean(val_scores_mse)\n",
    "    avg_mae = np.mean(val_scores_mae)\n",
    "    \n",
    "    print(f\"Average metrics for Revenue model: RÂ² = {avg_r2:.4f}, MSE = {avg_mse:.4f}, MAE = {avg_mae:.4f}\")\n",
    "    \n",
    "    # Re-fit on all training data\n",
    "    linear_model_rev.fit(X_rev_scaled, y_rev)\n",
    "    \n",
    "    # Save the model\n",
    "    joblib.dump((linear_model_rev, scaler_rev), 'models/stacking_linear_revenue.pkl')\n",
    "    \n",
    "    # Generate revenue predictions for test data\n",
    "    revenue_results = df_rev_test[['tic', 'datacqtr']].copy()\n",
    "    revenue_results['revenue_prediction'] = linear_model_rev.predict(X_rev_test_scaled)\n",
    "    \n",
    "    # CAR Stacking - Use more complex model (Random Forest) as recommended\n",
    "    print(\"\\n=== CAR Stacking ===\")\n",
    "    \n",
    "    # Prepare features for CAR prediction - Only use the model prediction columns\n",
    "    car_feature_cols = [col for col in df_car_train.columns if '_predict' in col]\n",
    "    print(f\"Using only these features for CAR stacking: {car_feature_cols}\")\n",
    "    \n",
    "    X_car = df_car_train[car_feature_cols].copy()\n",
    "    y_car = df_car_train['car5']\n",
    "    X_car_test = df_car_test[car_feature_cols].copy()\n",
    "    \n",
    "    print(f\"X_car shape: {X_car.shape}, y_car shape: {y_car.shape}\")\n",
    "    print(f\"X_car_test shape: {X_car_test.shape}\")\n",
    "    \n",
    "    # Use Random Forest for CAR as recommended\n",
    "    print(\"Training Random Forest for CAR stacking...\")\n",
    "    rf_model_car = RandomForestRegressor(\n",
    "        n_estimators=100, \n",
    "        max_depth=5,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Evaluate with cross-validation\n",
    "    val_scores_r2 = []\n",
    "    val_scores_mse = []\n",
    "    val_scores_mae = []\n",
    "    \n",
    "    for i, (train_idx, val_idx) in enumerate(cv_splits_car):\n",
    "        X_train, y_train = X_car.iloc[train_idx], y_car.iloc[train_idx]\n",
    "        X_val, y_val = X_car.iloc[val_idx], y_car.iloc[val_idx]\n",
    "        \n",
    "        # Train model\n",
    "        rf_model_car.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        val_preds = rf_model_car.predict(X_val)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        r2 = r2_score(y_val, val_preds)\n",
    "        mse = mean_squared_error(y_val, val_preds)\n",
    "        mae = np.mean(np.abs(y_val - val_preds))\n",
    "        \n",
    "        val_scores_r2.append(r2)\n",
    "        val_scores_mse.append(mse)\n",
    "        val_scores_mae.append(mae)\n",
    "        \n",
    "        print(f\"Fold {i+1}/{len(cv_splits_car)}: RÂ² = {r2:.4f}, MSE = {mse:.4f}, MAE = {mae:.4f}\")\n",
    "    \n",
    "    # Calculate average validation scores\n",
    "    avg_r2 = np.mean(val_scores_r2)\n",
    "    avg_mse = np.mean(val_scores_mse)\n",
    "    avg_mae = np.mean(val_scores_mae)\n",
    "    \n",
    "    print(f\"Average metrics for CAR model: RÂ² = {avg_r2:.4f}, MSE = {avg_mse:.4f}, MAE = {avg_mae:.4f}\")\n",
    "    \n",
    "    # Re-fit on all training data\n",
    "    rf_model_car.fit(X_car, y_car)\n",
    "    \n",
    "    # Save the model\n",
    "    joblib.dump(rf_model_car, 'models/stacking_randomforest_car.pkl')\n",
    "    \n",
    "    # Generate CAR predictions for test data\n",
    "    car_results = df_car_test[['tic', 'datacqtr']].copy()\n",
    "    car_results['car_prediction'] = rf_model_car.predict(X_car_test)\n",
    "    \n",
    "    # Return both DataFrames with predictions\n",
    "    return revenue_results, car_results\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the stacking pipeline\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Run the stacking pipeline - now returns two separate DataFrames\n",
    "        revenue_predictions, car_predictions = stacking_pipeline()\n",
    "        \n",
    "        # Save the predictions to separate files\n",
    "        revenue_predictions.to_csv('stacking_revenue_predictions.csv', index=False)\n",
    "        car_predictions.to_csv('stacking_car_predictions.csv', index=False)\n",
    "        \n",
    "        print(\"\\nStacking pipeline completed successfully!\")\n",
    "        print(\"Revenue predictions saved to 'stacking_revenue_predictions.csv'\")\n",
    "        print(\"CAR predictions saved to 'stacking_car_predictions.csv'\")\n",
    "        \n",
    "        # Try to merge predictions if tic and datacqtr match (without forcing)\n",
    "        print(\"\\nAttempting to merge predictions for common tic/datacqtr pairs...\")\n",
    "        merged_predictions = revenue_predictions.merge(\n",
    "            car_predictions, \n",
    "            on=['tic', 'datacqtr'], \n",
    "            how='inner',\n",
    "            suffixes=('', '_car')\n",
    "        )\n",
    "        \n",
    "        if len(merged_predictions) > 0:\n",
    "            merged_predictions.to_csv('stacking_merged_predictions.csv', index=False)\n",
    "            print(f\"Successfully merged {len(merged_predictions)} matching predictions saved to 'stacking_merged_predictions.csv'\")\n",
    "            print(\"\\nSample merged predictions:\")\n",
    "            print(merged_predictions.head(5))\n",
    "        else:\n",
    "            print(\"No matching tic/datacqtr pairs found between revenue and CAR predictions.\")\n",
    "        \n",
    "        # Display samples of individual predictions\n",
    "        print(\"\\nSample revenue predictions:\")\n",
    "        print(revenue_predictions.head(5))\n",
    "        print(\"\\nSample CAR predictions:\")\n",
    "        print(car_predictions.head(5))\n",
    "        \n",
    "        return revenue_predictions, car_predictions, merged_predictions if len(merged_predictions) > 0 else None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the main pipeline\n",
    "    final_predictions = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
